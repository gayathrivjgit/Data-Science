{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd8e57f9-7af3-44c7-a31c-286f11e109f1",
   "metadata": {},
   "source": [
    "# 1. Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b85fb5-6969-440a-8d67-a1c904dbfbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef01230-789a-4430-a894-75fbbe6ff03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('blogs_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc14c77-0621-4683-80fc-124c7b8a7680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Data</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:49...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Newsgroups: alt.atheism\\nPath: cantaloupe.srv....</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Data       Labels\n",
       "0           0  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:49...  alt.atheism\n",
       "1           1  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...  alt.atheism\n",
       "2           2  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
       "3           3  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...  alt.atheism\n",
       "4           4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...  alt.atheism"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c997191-bf5b-4209-8839-41bc5965869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Preprocess the text data by cleaning it.(Convert text to lowercase,Remove punctuation and special characters,Tokenize the text,Remove stopwords)\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords((common words like 'the', 'is' that don’t add much meaning))\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the 'Data' column\n",
    "df['cleaned_data'] = df['Data'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba6a64-75e5-46f0-a4dc-db60b50eaa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66954c44-a762-46f9-98d7-548805f31af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the text data into a numerical format using TF-IDF.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Adjust max_features based on your dataset size\n",
    "\n",
    "# Transform the text data\n",
    "X = tfidf.fit_transform(df['cleaned_data']).toarray()\n",
    "\n",
    "# The target labels (categories)\n",
    "y = df['Labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5646b6b-21d6-46b3-8b7f-5644c45b1501",
   "metadata": {},
   "source": [
    "# 2. Naive Bayes Model for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253efd23-30a9-47f8-80cb-b215c40ac310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and test sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e4377-2c01-4c6c-9028-129d9de43933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a Naive Bayes classifier and make predictions.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685da96-07fe-4561-beeb-09597924a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c622f970-be85-4c02-9e06-5943fd5947ed",
   "metadata": {},
   "source": [
    "# 3. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef94ad3-8ef1-4675-ae0e-3ee99c1f0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae307b7-e2d6-4088-9269-eb9dd2f8f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Function to get sentiment\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "# Apply sentiment analysis on the 'Data' column\n",
    "df['Sentiment'] = df['Data'].apply(get_sentiment)\n",
    "\n",
    "# Display sentiment distribution\n",
    "print(df['Sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac22707-4010-46f2-8e93-f3daba1da8ab",
   "metadata": {},
   "source": [
    "# Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2051b6-bcb3-4887-a65c-4d1ad3111045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sentiment distribution across all categories\n",
    "print(\"\\nSentiment distribution across all categories\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Sentiment', data=df)\n",
    "plt.title('Overall Sentiment Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Sentiment distribution within each category\n",
    "print(\"\\nSentiment distribution within each category\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Labels', hue='Sentiment', data=df)\n",
    "plt.title('Sentiment Distribution by Category')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6f727-890d-4f5b-9f4e-85de4ed2db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by categories and sentiment\n",
    "sentiment_distribution = df.groupby(['Labels', 'Sentiment']).size().unstack()\n",
    "print(sentiment_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df9b82-33e8-4635-ab28-3d5302fe076d",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f75827-0860-44af-8784-4540db131c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c562c",
   "metadata": {},
   "source": [
    "In conclusion, the Naive Bayes classifier, with proper preprocessing and feature extraction, can effectively categorize blog posts. Performance evaluation using metrics such as accuracy, precision, recall, and F1-score provides a comprehensive view of the model’s effectiveness. Challenges such as class imbalance and text preprocessing need careful handling to ensure robust performance.\n",
    "\n",
    "Sentiment analysis adds another layer of understanding, revealing the emotional tone of the blog posts. These insights can be crucial for content strategy, reader engagement, and marketing efforts.\n",
    "\n",
    "By combining text classification with sentiment analysis, you gain a powerful toolkit for extracting and leveraging insights from textual data, enhancing both the analytical and strategic capabilities of your organization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
